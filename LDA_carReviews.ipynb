{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec05c0f-0dff-4e62-a48e-068b46c6d414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c4ac3d-d0f0-41a7-b37f-4bcbc756ad50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "\n",
    "filesArray = os.listdir(f'{PATH}/archive')\n",
    "csvFiles = [file for file in filesArray if file.endswith(\".csv\")]\n",
    "csvFiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d04684f-90eb-49a1-a787-bcab14e6360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inchcapeReviews1.csv',\n",
       " 'inchcapeReviews2.csv',\n",
       " 'inchcapeReviews3.csv',\n",
       " 'inchcapeReviews4.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada1be9-d451-408c-966a-7e487c6c6274",
   "metadata": {},
   "source": [
    "#### combine to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4774171-9800-4d5c-adbc-7ed426507e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateExp</th>\n",
       "      <th>starRating</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>The garage refused to investigate a warrantee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>5</td>\n",
       "      <td>George Eden was fantastic. A pleasure to deal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>Extremely poor service from Sandhurst Inchcape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>5</td>\n",
       "      <td>As always I have had a very satisfying visit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>5</td>\n",
       "      <td>The customer agent Brook was superb. I found b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dateExp  starRating                                            reviews\n",
       "0 2023-05-09           1  The garage refused to investigate a warrantee ...\n",
       "1 2023-05-25           5  George Eden was fantastic. A pleasure to deal ...\n",
       "2 2023-05-23           1  Extremely poor service from Sandhurst Inchcape...\n",
       "3 2023-05-19           5  As always I have had a very satisfying visit t...\n",
       "4 2023-05-18           5  The customer agent Brook was superb. I found b..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one data frame\n",
    "data = []\n",
    "for i in csvFiles:\n",
    "    data.append(pd.read_csv(f'{PATH}/archive/{i}'))\n",
    "\n",
    "reviewsRaw = pd.concat(data, ignore_index=True)\n",
    "\n",
    "columnNames = {'Date of Exp' : 'dateExp', 'Star Rating' : 'starRating', 'Reviews': 'reviews'}\n",
    "reviewsRaw = reviewsRaw.rename(columns=columnNames)\n",
    "\n",
    "reviewsRaw['dateExp'] = pd.to_datetime(reviewsRaw['dateExp'], format = 'mixed')\n",
    "reviewsRaw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d8c9c-2743-4c98-bc91-6fce42411b19",
   "metadata": {},
   "source": [
    "### maybe include date filter here?\n",
    "\n",
    "treat onedate = onedocument\n",
    "\n",
    "topics modelling will be per day (or according to desired range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf23cb3-5865-474d-a6e0-abe3955ccbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1327, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to get only the rows from 2023\n",
    "reviews = reviewsRaw.loc[reviewsRaw['dateExp'].dt.year >= 2022].copy()\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde07456-df65-4e9a-a852-724164702607",
   "metadata": {},
   "source": [
    "> By using the .loc accessor and the .copy() method, you explicitly indicate that you want to modify a specific subset of the DataFrame, avoiding the warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4d007-b38a-4114-8eff-ce6a3a91d615",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c0162-db32-4639-a39f-848559461c30",
   "metadata": {},
   "source": [
    "#### remove words with just two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4b9d1f-761f-4fb5-ab69-6b6998a4a897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews[reviews['reviews'].str.split().str.len() > 2]\n",
    "reviews = reviews.reset_index(drop=True)\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c0c87d-eaac-435b-8d92-ff51bd7ba4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14809, 3)\n",
      "(1300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(reviewsRaw.shape, reviews.shape, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f2516-e2e7-4b9d-9160-c83b0be4fbb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### recode starRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297aec50-6753-427c-99d6-d1d6fad5aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['starRatingRecode'] = reviews['starRating'].apply(lambda x: 'positive' if x >=4 else ('neutral' if x==3 else 'negative'))\n",
    "reviews.head()\n",
    "#print(reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3178b-44f8-4b3f-b639-e0c21cf6360b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### remove puctuations & convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e923d69d-7dcd-4a56-8876-20089a49729d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lowerCase_removePunc(dataframeName, columnName):\n",
    "    dataframeName[columnName] = dataframeName['reviews'].map(lambda text: re.sub(r'[,\\.!?]', '', text))\n",
    "    dataframeName[columnName] = dataframeName[columnName].map(lambda text: text.lower())    \n",
    "    return dataframeName\n",
    "\n",
    "\n",
    "#reviews = lowerCase_removePunc(reviews, 'processedText')\n",
    "#reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79ed08-cf53-4267-baf3-6a51ecb07e28",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309c3a0-4fac-498b-b286-e7bcc099f2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = (reviews['processedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e712f3e5-7a4a-441b-8a19-a7293f5b2839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "#processedText = content.apply(tokenize)\n",
    "#processedText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda494c5-218e-4b5e-9f8e-61412a30b7e1",
   "metadata": {},
   "source": [
    "#### remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aace5901-5b4e-48c8-bcc6-115b897c3cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords  = stopwords.words('english')\n",
    "#stopwords\n",
    "\n",
    "def removeStopwords(tokenizedText):\n",
    "    filteredTokens = [token for token in tokenizedText if token.lower() not in stopwords]\n",
    "    return filteredTokens\n",
    "\n",
    "#processedText = processedText.apply(removeStopwords)\n",
    "#processedText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b1ddc-75ed-4d62-bb27-70da11b23419",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f7dd5-0bdd-4505-9800-fe5839528659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "longString = ' '.join(processedText.apply(lambda x: ' '.join(x))) #combine into one long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a3931-bbb4-4558-8a9e-441f7de8bcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(scale = 3,\n",
    "        background_color='white',\n",
    "        max_words=250,\n",
    "        max_font_size=40,\n",
    "        colormap='BrBG',\n",
    "        random_state=42                      \n",
    "    ).generate(longString)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7b986-4eec-4f7b-9dc4-67ed23039e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the wordcloud image\n",
    "wordcloud_image_path = 'wordcloud.png'  # Specify the path and filename\n",
    "wordcloud.to_file(wordcloud_image_path)\n",
    "print(f\"Wordcloud saved as {wordcloud_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa107d59-935c-4ed2-aa71-8dd72be2646f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921d87e0-881c-4fec-b983-0f5a98a3bbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(tokenizedText):\n",
    "    filteredTokens = [lemmatizer.lemmatize(token) for token in tokenizedText]\n",
    "    return filteredTokens\n",
    "\n",
    "#processedText = processedText.apply(lemmatize)\n",
    "#processedText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814d97b-72d8-4f2d-b3c5-acd7f0097aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modelling using LDA-gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6f46f2-7499-4fa6-b6e7-28561c8cd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Prepare the corpus\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess \n",
    "# simple_preprocess:\n",
    "# tokenization, lowercasing,\n",
    "# filtering removes tokens that are too short (less than 3 characters) or too long (more than 15 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8556bd41-4f21-44c0-81e3-6222123e65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = (reviews['reviews'])\n",
    "corpus = []\n",
    "\n",
    "def preprocess_corpus(data):\n",
    "    processed_corpus = data.apply(lambda x: simple_preprocess(x))\n",
    "    return processed_corpus\n",
    "\n",
    "#preprocessed_corpus = preprocess_corpus(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da14035f-6414-4225-898e-614b7e59b635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The garage refused to investigate a warrantee ...\n",
       "1    George Eden was fantastic. A pleasure to deal ...\n",
       "2    Extremely poor service from Sandhurst Inchcape...\n",
       "3    As always I have had a very satisfying visit t...\n",
       "4    The customer agent Brook was superb. I found b...\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73eadcc-7f52-4cd2-b8ea-3a5ebd6946f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: Creating dictionary\n",
    "from nltk import bigrams\n",
    "from gensim import corpora, models\n",
    "\n",
    "def create_bigrams(corpus):\n",
    "    # Create a list to hold the bigram models\n",
    "    corpus_bigrams = []\n",
    "\n",
    "    # Create bigrams for each document in the corpus\n",
    "    for doc in corpus:\n",
    "        doc_bigrams = list(bigrams(doc))\n",
    "        doc_bigrams = [' '.join(bigram) for bigram in doc_bigrams]  # Convert bigrams to strings\n",
    "        corpus_bigrams.append(doc_bigrams)\n",
    "\n",
    "    return corpus_bigrams\n",
    "\n",
    "def create_dict(corpus):\n",
    "    # create dict using the preprocessed corpus\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    \n",
    "    # create bag-of-words representation of the corpus\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "    \n",
    "    # create tf-idf model and convert the bow vector to tfidf vectors\n",
    "    tfidf_model = models.TfidfModel(bow_corpus)\n",
    "    tfidf_corpus = tfidf_model[bow_corpus]\n",
    "    \n",
    "    corpus_vecs = tfidf_corpus\n",
    "    return dictionary, corpus_vecs,tfidf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6aeb043-c25d-4fdd-84b5-9597e9acf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing steps to the corpus\n",
    "preprocessed_corpus = preprocess_corpus(content)\n",
    "preprocessed_corpus = preprocessed_corpus.apply(removeStopwords)\n",
    "preprocessed_corpus = preprocessed_corpus.apply(lemmatize)\n",
    "\n",
    "# Create the bigrams in the corpus\n",
    "corpus_bigrams = create_bigrams(preprocessed_corpus)\n",
    "\n",
    "# Create the dictionary and TF-IDF corpus with bigrams\n",
    "dictionary, corpus_vecs, tfidf_model = create_dict(corpus_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf81139-ef49-4c91-b05e-9a6437aa4270",
   "metadata": {},
   "source": [
    "> By incorporating the TF-IDF transformation, you can assign higher weights to terms that are important in a particular document while downweighting terms that are common across multiple documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7926ee-5b0a-42e0-a2bd-c813b4d77d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build LDA model\n",
    "\n",
    "def train_lda_model(corpus, num_topics):\n",
    "    # Train lda model on tf-idf corpus\n",
    "    lda_model = models.LdaModel(corpus=corpus,\n",
    "                                num_topics=num_topics,\n",
    "                                id2word=dictionary,\n",
    "                                passes=20)\n",
    "    \n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb10a14b-2193-4d5a-98e4-7299037fe569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.2 s, sys: 64.6 ms, total: 8.26 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_topics = 5\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model_gensim = train_lda_model(corpus_vecs, num_topics)\n",
    "\n",
    "# Print the topics and their corresponding keywords\n",
    "# for topic_id, topic_words in lda_model_gensim.print_topics():\n",
    "#    print(f\"Topic #{topic_id+1}: {topic_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28acebbd-b359-4627-b6a1-63cdbe260687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics_df(lda_model, corpus_vecs, num_topics):\n",
    "    # Assign topics to documents\n",
    "    document_topics = []\n",
    "    for i, doc in enumerate(corpus_vecs):\n",
    "        doc_topics = lda_model.get_document_topics(doc)\n",
    "        document_topics.append([prob for _, prob in doc_topics])\n",
    "\n",
    "    # Convert document_topics into a DataFrame\n",
    "    topics_df = pd.DataFrame(document_topics)\n",
    "\n",
    "    # Rename the columns to represent topics\n",
    "    topics_df.columns = [f\"Topic_{i+1}\" for i in range(num_topics)]\n",
    "    \n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e4b9733-283f-4d9f-8d37-e694077da405",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = generate_topics_df(lda_model_gensim, corpus_vecs, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09174df-ac11-4233-baff-94baea49cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>processedReviews</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The garage refused to investigate a warrantee ...</td>\n",
       "      <td>[garage, refused, investigate, warrantee, faul...</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>0.032404</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>0.870521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Eden was fantastic. A pleasure to deal ...</td>\n",
       "      <td>[george, eden, fantastic, pleasure, deal, comm...</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.038488</td>\n",
       "      <td>0.038683</td>\n",
       "      <td>0.845629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely poor service from Sandhurst Inchcape...</td>\n",
       "      <td>[extremely, poor, service, sandhurst, inchcape...</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.893041</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.026705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As always I have had a very satisfying visit t...</td>\n",
       "      <td>[always, satisfying, visit, inchcape, toyota, ...</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.026180</td>\n",
       "      <td>0.025730</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>0.896472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The customer agent Brook was superb. I found b...</td>\n",
       "      <td>[customer, agent, brook, superb, found, manage...</td>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.036750</td>\n",
       "      <td>0.037153</td>\n",
       "      <td>0.037085</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews   \n",
       "0  The garage refused to investigate a warrantee ...  \\\n",
       "1  George Eden was fantastic. A pleasure to deal ...   \n",
       "2  Extremely poor service from Sandhurst Inchcape...   \n",
       "3  As always I have had a very satisfying visit t...   \n",
       "4  The customer agent Brook was superb. I found b...   \n",
       "\n",
       "                                    processedReviews   Topic_1   Topic_2   \n",
       "0  [garage, refused, investigate, warrantee, faul...  0.032351  0.032379  \\\n",
       "1  [george, eden, fantastic, pleasure, deal, comm...  0.038741  0.038458   \n",
       "2  [extremely, poor, service, sandhurst, inchcape...  0.026790  0.893041   \n",
       "3  [always, satisfying, visit, inchcape, toyota, ...  0.025761  0.026180   \n",
       "4  [customer, agent, brook, superb, found, manage...  0.037013  0.036750   \n",
       "\n",
       "    Topic_3   Topic_4   Topic_5  \n",
       "0  0.032404  0.032345  0.870521  \n",
       "1  0.038488  0.038683  0.845629  \n",
       "2  0.026728  0.026735  0.026705  \n",
       "3  0.025730  0.025857  0.896472  \n",
       "4  0.037153  0.037085  0.852000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge topics_df with existing reviews DataFrame\n",
    "processedReviews = preprocessed_corpus.rename('processedReviews')\n",
    "\n",
    "reviewsNtopics = pd.concat([reviews['reviews'], processedReviews, topics_df], axis=1)\n",
    "reviewsNtopics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdb8c915-5433-4861-95eb-895973b14923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Analyze topics\n",
    "\n",
    "# Get the top keywords for each topic\n",
    "# topics = lda_model_gensim.show_topics(num_topics=num_topics, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc186d7-a741-4c76-ade4-5dafa360bbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Visualize\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import webbrowser\n",
    "\n",
    "# Visualize the topics\n",
    "vis_data = gensimvis.prepare(lda_model_gensim, corpus_vecs, dictionary)\n",
    "\n",
    "# Convert the document-topic assignments to a format suitable for visualization\n",
    "vis_data = pyLDAvis.gensim_models.prepare(lda_model_gensim, corpus_vecs, dictionary)\n",
    "\n",
    "pyLDAvis.save_html(vis_data, 'lda_visualization.html')\n",
    "webbrowser.open('lda_visualization.html', new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeac9c1-ad10-4b8d-b207-1a5768bfe766",
   "metadata": {},
   "source": [
    "## Summarize using Hugging Face Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce752197-bc27-4082-9181-d96b6e4ab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db8753-26a3-4a29-8a01-6284632f9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"bert-base-uncased\"\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"model_name\")\n",
    "#summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7686223f-db33-42d9-8db0-1eac71f36003",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccb64f00-dc80-42f6-a94a-cdf94e9b22ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286048"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE = ' '.join(preprocessed_corpus.apply(lambda x: ' '.join(x)))\n",
    "#ARTICLE = ARTICLE[:1000]\n",
    "len(ARTICLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88cfe966-9fb1-4cf7-9c9c-0bea8cac306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'There was a six-week wait for a car to be delivered. Garage refused to investigate warrantee fault. The car was delivered on time, but it was damaged. It was repaired and sold to a dealership.'}]\n",
      "CPU times: user 56.4 s, sys: 26.7 s, total: 1min 23s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(summarizer(ARTICLE[:5000], max_length=150, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e43167-ca9e-4172-ad76-80317ba947c3",
   "metadata": {},
   "source": [
    "## Create summary for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a0b9887-13b7-4301-8274-7c105b05b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate dataframes for each topic\n",
    "threshold = 1 / num_topics\n",
    "\n",
    "topic_dataframes = {}\n",
    "\n",
    "for column in topics_df.columns:\n",
    "    topic_reviews = reviewsNtopics[reviewsNtopics[column] >= threshold]  # Filter reviews with score greater than or equal to threshold\n",
    "    topic_dataframes[column] = topic_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9778c2c-2cf6-4280-8fed-3222fa960572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>processedReviews</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely poor service from Sandhurst Inchcape...</td>\n",
       "      <td>[extremely, poor, service, sandhurst, inchcape...</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.893041</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.026705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I purchased a used car from Cheshire Oaks Audi...</td>\n",
       "      <td>[purchased, used, car, cheshire, oak, audi, se...</td>\n",
       "      <td>0.051484</td>\n",
       "      <td>0.790643</td>\n",
       "      <td>0.053999</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.051937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Failed home delivery twice , salesperson faile...</td>\n",
       "      <td>[failed, home, delivery, twice, salesperson, f...</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>0.819447</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>0.045138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Had a service @ Landrover, Chester yesterday Y...</td>\n",
       "      <td>[service, landrover, chester, yesterday, yd, n...</td>\n",
       "      <td>0.044727</td>\n",
       "      <td>0.820816</td>\n",
       "      <td>0.044765</td>\n",
       "      <td>0.044738</td>\n",
       "      <td>0.044954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sold a car in the past couple of weeks - Inchc...</td>\n",
       "      <td>[sold, car, past, couple, week, inchcape, gave...</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.908674</td>\n",
       "      <td>0.022896</td>\n",
       "      <td>0.023127</td>\n",
       "      <td>0.022668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Please take car when buying an older vehicle f...</td>\n",
       "      <td>[please, take, car, buying, older, vehicle, ga...</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.024005</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.023966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>Preston Jaguar Land Rover : One of the worst b...</td>\n",
       "      <td>[preston, jaguar, land, rover, one, worst, buy...</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.916035</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.020995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Inchcape Stockport VW Garage:\\nTerrible Experi...</td>\n",
       "      <td>[inchcape, stockport, vw, garage, terrible, ex...</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>0.855022</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036181</td>\n",
       "      <td>0.036316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Best service I have had in general for years, ...</td>\n",
       "      <td>[best, service, general, year, year, lady, ser...</td>\n",
       "      <td>0.033093</td>\n",
       "      <td>0.867390</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>0.033011</td>\n",
       "      <td>0.033269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>My husband &amp; I had our cars serviced in Decemb...</td>\n",
       "      <td>[husband, car, serviced, december, lovely, abl...</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.860649</td>\n",
       "      <td>0.034802</td>\n",
       "      <td>0.034768</td>\n",
       "      <td>0.034781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews   \n",
       "2     Extremely poor service from Sandhurst Inchcape...  \\\n",
       "11    I purchased a used car from Cheshire Oaks Audi...   \n",
       "13    Failed home delivery twice , salesperson faile...   \n",
       "14    Had a service @ Landrover, Chester yesterday Y...   \n",
       "15    Sold a car in the past couple of weeks - Inchc...   \n",
       "...                                                 ...   \n",
       "1258  Please take car when buying an older vehicle f...   \n",
       "1260  Preston Jaguar Land Rover : One of the worst b...   \n",
       "1272  Inchcape Stockport VW Garage:\\nTerrible Experi...   \n",
       "1294  Best service I have had in general for years, ...   \n",
       "1299  My husband & I had our cars serviced in Decemb...   \n",
       "\n",
       "                                       processedReviews   Topic_1   Topic_2   \n",
       "2     [extremely, poor, service, sandhurst, inchcape...  0.026790  0.893041  \\\n",
       "11    [purchased, used, car, cheshire, oak, audi, se...  0.051484  0.790643   \n",
       "13    [failed, home, delivery, twice, salesperson, f...  0.045138  0.819447   \n",
       "14    [service, landrover, chester, yesterday, yd, n...  0.044727  0.820816   \n",
       "15    [sold, car, past, couple, week, inchcape, gave...  0.022636  0.908674   \n",
       "...                                                 ...       ...       ...   \n",
       "1258  [please, take, car, buying, older, vehicle, ga...  0.023976  0.904087   \n",
       "1260  [preston, jaguar, land, rover, one, worst, buy...  0.021038  0.916035   \n",
       "1272  [inchcape, stockport, vw, garage, terrible, ex...  0.036236  0.855022   \n",
       "1294  [best, service, general, year, year, lady, ser...  0.033093  0.867390   \n",
       "1299  [husband, car, serviced, december, lovely, abl...  0.034999  0.860649   \n",
       "\n",
       "       Topic_3   Topic_4   Topic_5  \n",
       "2     0.026728  0.026735  0.026705  \n",
       "11    0.053999  0.051937  0.051937  \n",
       "13    0.045138  0.045138  0.045138  \n",
       "14    0.044765  0.044738  0.044954  \n",
       "15    0.022896  0.023127  0.022668  \n",
       "...        ...       ...       ...  \n",
       "1258  0.024005  0.023966  0.023966  \n",
       "1260  0.020963  0.020969  0.020995  \n",
       "1272  0.036246  0.036181  0.036316  \n",
       "1294  0.033237  0.033011  0.033269  \n",
       "1299  0.034802  0.034768  0.034781  \n",
       "\n",
       "[255 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dataframes['Topic_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cb85310-350c-4e7f-b7b2-baff8e5c3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_summary(corpus, length_limit):\n",
    "    if len(corpus) == 0:\n",
    "        return \"Corpus is empty.\"\n",
    "\n",
    "    article = ' '.join(corpus.apply(lambda x: ' '.join(x)))\n",
    "    #article = ' '.join(corpus)\n",
    "    article_length = len(article)\n",
    "\n",
    "    if article_length <= length_limit:\n",
    "        start_idx = 0\n",
    "        end_idx = article_length\n",
    "    else:\n",
    "        start_idx = random.randint(0, article_length - length_limit)\n",
    "        end_idx = start_idx + length_limit\n",
    "    \n",
    "    article_chunk = article[start_idx:end_idx]\n",
    "    \n",
    "    # Generate the summary using the pre-initialized summarizer pipeline\n",
    "    summary = summarizer(article_chunk, max_length=100, min_length=30, do_sample=False)\n",
    "    \n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Function to generate random summaries for each topic\n",
    "def generate_random_topic_summaries(topic_dataframes, length_limit):\n",
    "    topic_summaries = {}\n",
    "\n",
    "    for topic, dataframe in topic_dataframes.items():\n",
    "        reviews = dataframe['processedReviews']\n",
    "        random_summary = generate_random_summary(reviews, length_limit)\n",
    "        topic_summaries[topic] = random_summary\n",
    "\n",
    "    return topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "004478e0-5da6-449d-af6c-0c894053de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 100, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 100, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but you input_length is only 74. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 100, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Topic_1: Audi dealer ignored car develops fault and didn't fix it. They called back on Wednesday morning and fixed the problem. The previous dealership had already given previous review.\n",
      "Summary for Topic_2: Clude warranty provider is refusing to repair bodywork on a customer's car. The last email regarding bodywork damage was sent before the previous service.\n",
      "Summary for Topic_3: Dan Paul's son bought a new volkswagen at random drop in Altrincham. The car was well-serviced and the service was good.\n",
      "Summary for Topic_4: The warrington car repair exceeded expectations and the work will be charged. The service engineer working on the car previously failed to reserve part allocated to a different branch, so it had to be reordered and delayed.\n",
      "Summary for Topic_5: Autotrader advert state bmw series fully prepared ready next journey delivered location collected whenever suit state within mile informed mile away. Richard charge service helpful knowledgeable approachable.\n"
     ]
    }
   ],
   "source": [
    "length_limit = 500  # Adjust the length limit as needed\n",
    "topic_summaries = generate_random_topic_summaries(topic_dataframes, length_limit)\n",
    "\n",
    "# Display the random summaries\n",
    "for topic, summary in topic_summaries.items():\n",
    "    print(f\"Summary for {topic}: {summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
